##### 问题一：为什么使用消息队列？

​	主要从使用`MQ`的好处去理解。使用`MQ`常见的好处有：解耦，异步（性能提高），流量削峰。

​	**解耦**：为其他多个服务提供关键数据的服务，这个服务需要向其他系统推送数据，当其他系统拿到数据之后做不同的处理，这时候如果不使用`MQ`，那么就需要逐个系统去调用接口，而且需要等每个接口调用成功之后再继续调用下一个系统的接口，这样的操作耦合度高，并且接口的响应时间很长，一旦要在原来调用的系统接口基础上增加或者减少，那么都会去修改这个关键服务的代码，并且当其他系统的接口处理时间比较长或者需要调用的接口数量比较多的时候，系统的延时会大大增加，这样大幅度降低了用户体验。

​	**异步**：比如系统的日志记录，当不使用异步的时候，我们每次 都需要去调用系统的日志服务记录日志的接口，这样一来只有当日志记录完成之后才能返回数据给客户端，每个接口都是如此，极大地降低了接口性能。当使用`MQ`之后，我们只需要将日志信息加入至的队列之中，我们就不用了管日志的后续操作了，可以直接将数据返回至客户端。这样就提高了每个接口的性能。（日志的实现：注解+`AOP`+`MQ`）

​	**流量削峰**：

##### 问题二：如何保证`MQ`的高可用

​	`RabbitMQ`：`RabbitMQ`的工作模式有三种

​		单机模式：不适合生产环境，掉了就没了。

​		集群模式：

​		镜像集群模式：

​	`Kafka`：

##### 问题三：如何保证消息不被重复消费

​	`RabbitMQ`:关闭了自动`ack`，当消费者消费完成时候没来得及提交`ack`消费者就挂了，当重启消费者之后又会从`MQ`中拿到重复的消息。（`kafka`同理）

##### 问题四：如何保证消息不丢失

​	`RabbitMQ`：消息丢失有三个环节。

​		生产者生产出了消息放入`MQ`的时候失败了。解决方案分为开始事务和开启`confirm`模式，一般是选择后者。当开始`confirm`模式之后，每次写消息都会分配一个消息`ID`,每次写入成功会回调一个`ConfirmListener`接口的`ack`方法，每次失败会回调`nack`方法，当失败的时候只需要重写这个`noack`接口的方法，重新发送消息即可。配置方法：在`application.yml`文件开启`confirm`模式

​		消费者还没消费到消息，`MQ`就挂了。解决方案：`MQ`持久化（创建队列的时候持久化），发送的消息持久化（发送消息的时候设置持久化属性）。

​		消费者刚从`MQ`消费了消息，但是拿到消息还没来得及处理就挂了（要开启自动`ack`才会出现）。解决方案：关闭自动`ack`的功能，每次消费完消息之后，自己手动`ack`。

`kafka`:在`MQ`的服务端消息丢失只有一个环节，就是生产者生产的消息刚放入到`broker` 的`leader`，此时的`leader`还未来得及讲消息同步到`follower`,`leader`就挂了，而没有收到最新消息的`follower`又被选举成了`learder`

​		在消费端消息丢失也只有一个环节，就是未关闭自动提交`offset`,当消费者刚拿到消息，还未来得及处理，然后就自动提交了`offset`。解决方案：关闭自动提交`offset`

##### 问题五：如何保证消息的消费顺序

##### 问题六：`MQ`的选型

##### 问题七：消息积压过多怎么办

##### 问题八：如何设计一个消息中间件

​	支持扩容，分布式的`MQ`参考kafka的历练，一个topic多个broker，一个broker多个partition，写磁盘，挂了的保证机制，leader和follower的选举，一个leader多个follower，消息丢失（手动ack），重复

消费者的性能提高：多线程，内存Queue（保证消息的顺序性）

`RabbitMQ`可以设置过期时间li