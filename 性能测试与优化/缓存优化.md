[TOC]

# 缓存与分布式锁

合适放入缓存的数据

1. 即时性，数据一致性要求不高的
2. 访问量大，更新频率不高的数据

## 整合`redis`

1. 添加依赖

```xml
<dependency>
	<groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
```

2. 自动配置类

```java
//
// Source code recreated from a .class file by IntelliJ IDEA
// (powered by Fernflower decompiler)
//

package org.springframework.boot.autoconfigure.data.redis;

import java.net.UnknownHostException;
import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;
import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;
import org.springframework.boot.context.properties.EnableConfigurationProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Import;
import org.springframework.data.redis.connection.RedisConnectionFactory;
import org.springframework.data.redis.core.RedisOperations;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.data.redis.core.StringRedisTemplate;

@Configuration
@ConditionalOnClass({RedisOperations.class})
@EnableConfigurationProperties({RedisProperties.class})
// 导入了两个客户端的连接
@Import({LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class})
public class RedisAutoConfiguration {
    public RedisAutoConfiguration() {
    }

    @Bean
    @ConditionalOnMissingBean(
        name = {"redisTemplate"}
    )
    public RedisTemplate<Object, Object> redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException {
        RedisTemplate<Object, Object> template = new RedisTemplate();
        template.setConnectionFactory(redisConnectionFactory);
        return template;
    }

    @Bean
    @ConditionalOnMissingBean
    public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException {
        StringRedisTemplate template = new StringRedisTemplate();
        template.setConnectionFactory(redisConnectionFactory);
        return template;
    }
}

```

3. `redis`的相关配置

```yml
spring:
  redis:
  	host: 192.168.56.10
  	port: 6379
  	  
```

4. 单元测试

```java
   /**
     * stringRedisTemplate.opsForHash(); // Map类型
     * stringRedisTemplate.opsForList(); // 数组类型
     * stringRedisTemplate.opsForSet();   // 集合类型
     * stringRedisTemplate.opsForValue(); // String类型
     * stringRedisTemplate.opsForZSet();  // 排序的集合
     * 存JSON字符串的好处：跨平台跨语言的，其他语言的系统都可以拿出来反序列化成对象
     */
    @Test
    public void testStringRedisTemplate() {
        ValueOperations<String, String> ops = stringRedisTemplate.opsForValue();
        // 设置值
        ops.set("hello", "hello world: " + UUID.randomUUID());
        // 查询
        String hello = ops.get("hello");
        System.err.println(hello);
    }
```

5. 改造三级分类业务

- 改造之前代码

```java
public Map<String, List<Catelog2Vo>> getCatelogJsonFromDB() {
        // 接口优化：将所有的数据一次查询出来，后面的查询在该数据集中遍历查询，减少数据库的交互
        List<CategoryEntity> levelOneList = getLevelOneList();
        Map<String, List<Catelog2Vo>> collect = levelOneList.stream().collect(Collectors.toMap(k -> k.getCatId().toString(), v -> {
            // 封装catelog2VO的列表
            List<CategoryEntity> levelTwoList = list(new QueryWrapper<CategoryEntity>().eq("parent_cid", v.getCatId()));
            List<Catelog2Vo> catelog2VoList = new ArrayList<>();
            if (!CollectionUtils.isEmpty(levelTwoList)) {
                catelog2VoList = levelTwoList.stream().map(two -> {
                    // 查询三级分类列表
                    List<CategoryEntity> levelThreeList = list(new QueryWrapper<CategoryEntity>().eq("parent_cid", two.getCatId()));
                    List<Catelog2Vo.Catelog3Vo> catelog3VoList = new ArrayList<>();
                    if (!CollectionUtils.isEmpty(levelThreeList)) {
                        catelog3VoList = levelThreeList.stream().map(three -> {
                            Catelog2Vo.Catelog3Vo catelog3Vo = new Catelog2Vo.Catelog3Vo(two.getCatId().toString(), three.getCatId().toString(), three.getName());
                            return catelog3Vo;
                        }).collect(Collectors.toList());
                    }
                    Catelog2Vo catelog2Vo = new Catelog2Vo(v.getCatId().toString(), catelog3VoList, two.getCatId().toString(), two.getName());
                    return catelog2Vo;
                }).collect(Collectors.toList());
            }
            return catelog2VoList;
        }));
        return collect;
    }
```



- 改造之后代码

```java
@Override
    public Map<String, List<Catelog2Vo>> getCatelogJson() {
        String catalogJson = stringRedisTemplate.opsForValue().get(CacheConstant.ProductCacheKeyEnum.CATALOG_JSON.getCode());
        if (StringUtils.isEmpty(catalogJson)) {
            Map<String, List<Catelog2Vo>> catelogJsonFromDB = getCatelogJsonFromDB();
            stringRedisTemplate.opsForValue().set(CacheConstant.ProductCacheKeyEnum.CATALOG_JSON.getCode(), JSON.toJSONString(catelogJsonFromDB));
            return catelogJsonFromDB;
        }
        Map<String, List<Catelog2Vo>> stringListMap = JSON.parseObject(catalogJson, new TypeReference<Map<String, List<Catelog2Vo>>>() {
        });
        return stringListMap;
    }

```



#### 压测时发生堆外内存溢出

![](F:\桌面文件\学习文件\images\redis堆外内存溢出.png)

- 发生原因

`spring-boot-data-redis 2.1.8.RELEASE`默认使用的`redis`的客户端是

```xml
<dependency>
    <groupId>io.lettuce</groupId>
    <artifactId>lettuce-core</artifactId>
    <version>5.1.8.RELEASE</version>
    <scope>compile</scope>
</dependency>
```

而`lettuce`使用的是`netty`进行网络通讯

`lettuce`的`bug`导致`netty`堆外内存(直接内存)溢出

netty当没有指定堆外内存的时候，默认使用的堆外内存就是当前堆内存的大小

```java
 static {
        BIG_ENDIAN_NATIVE_ORDER = ByteOrder.nativeOrder() == ByteOrder.BIG_ENDIAN;
        NOOP = new Cleaner() {
            public void freeDirectBuffer(ByteBuffer buffer) {
            }
        };
        if (javaVersion() >= 7) {
            RANDOM_PROVIDER = new PlatformDependent.ThreadLocalRandomProvider() {
                public Random current() {
                    return ThreadLocalRandom.current();
                }
            };
        } else {
            RANDOM_PROVIDER = new PlatformDependent.ThreadLocalRandomProvider() {
                public Random current() {
                    return io.netty.util.internal.ThreadLocalRandom.current();
                }
            };
        }

        long maxDirectMemory = SystemPropertyUtil.getLong("io.netty.maxDirectMemory", -1L);
        if (maxDirectMemory != 0L && hasUnsafe() && PlatformDependent0.hasDirectBufferNoCleanerConstructor()) {
            USE_DIRECT_BUFFER_NO_CLEANER = true;
            if (maxDirectMemory < 0L) {
                maxDirectMemory = MAX_DIRECT_MEMORY;
                if (maxDirectMemory <= 0L) {
                    DIRECT_MEMORY_COUNTER = null;
                } else {
                    DIRECT_MEMORY_COUNTER = new AtomicLong();
                }
            } else {
                DIRECT_MEMORY_COUNTER = new AtomicLong();
            }
        } else {
            USE_DIRECT_BUFFER_NO_CLEANER = false;
            DIRECT_MEMORY_COUNTER = null;
        }

        logger.debug("-Dio.netty.maxDirectMemory: {} bytes", maxDirectMemory);
        DIRECT_MEMORY_LIMIT = maxDirectMemory >= 1L ? maxDirectMemory : MAX_DIRECT_MEMORY;
        int tryAllocateUninitializedArray = SystemPropertyUtil.getInt("io.netty.uninitializedArrayAllocationThreshold", 1024);
        UNINITIALIZED_ARRAY_ALLOCATION_THRESHOLD = javaVersion() >= 9 && PlatformDependent0.hasAllocateArrayMethod() ? tryAllocateUninitializedArray : -1;
        logger.debug("-Dio.netty.uninitializedArrayAllocationThreshold: {}", UNINITIALIZED_ARRAY_ALLOCATION_THRESHOLD);
        MAYBE_SUPER_USER = maybeSuperUser0();
        if (!isAndroid()) {
            if (javaVersion() >= 9) {
                CLEANER = (Cleaner)(CleanerJava9.isSupported() ? new CleanerJava9() : NOOP);
            } else {
                CLEANER = (Cleaner)(CleanerJava6.isSupported() ? new CleanerJava6() : NOOP);
            }
        } else {
            CLEANER = NOOP;
        }

        DIRECT_BUFFER_PREFERRED = CLEANER != NOOP && !SystemPropertyUtil.getBoolean("io.netty.noPreferDirect", false);
        if (logger.isDebugEnabled()) {
            logger.debug("-Dio.netty.noPreferDirect: {}", !DIRECT_BUFFER_PREFERRED);
        }

        if (CLEANER == NOOP && !PlatformDependent0.isExplicitNoUnsafe()) {
            logger.info("Your platform does not provide complete low-level API for accessing direct buffers reliably. Unless explicitly requested, heap buffer will always be preferred to avoid potential system instability.");
        }

        String[] OS_RELEASE_FILES = new String[]{"/etc/os-release", "/usr/lib/os-release"};
        String LINUX_ID_PREFIX = "ID=";
        String LINUX_ID_LIKE_PREFIX = "ID_LIKE=";
        Set<String> allowedClassifiers = new HashSet(Arrays.asList(ALLOWED_LINUX_OS_CLASSIFIERS));
        Set<String> allowedClassifiers = Collections.unmodifiableSet(allowedClassifiers);
        Set<String> availableClassifiers = new LinkedHashSet();
        String[] var8 = OS_RELEASE_FILES;
        int var9 = OS_RELEASE_FILES.length;

        label281:
        for(int var10 = 0; var10 < var9; ++var10) {
            String osReleaseFileName = var8[var10];
            File file = new File(osReleaseFileName);
            if (file.exists()) {
                BufferedReader reader = null;

                try {
                    reader = new BufferedReader(new InputStreamReader(new FileInputStream(file), CharsetUtil.UTF_8));

                    while(true) {
                        String line;
                        if ((line = reader.readLine()) == null) {
                            break label281;
                        }

                        if (line.startsWith("ID=")) {
                            String id = normalizeOsReleaseVariableValue(line.substring("ID=".length()));
                            addClassifier(allowedClassifiers, availableClassifiers, id);
                        } else if (line.startsWith("ID_LIKE=")) {
                            line = normalizeOsReleaseVariableValue(line.substring("ID_LIKE=".length()));
                            addClassifier(allowedClassifiers, availableClassifiers, line.split("[ ]+"));
                        }
                    }
                } catch (IOException var24) {
                    break;
                } finally {
                    if (reader != null) {
                        try {
                            reader.close();
                        } catch (IOException var23) {
                            ;
                        }
                    }

                }
            }
        }

        LINUX_OS_CLASSIFIERS = Collections.unmodifiableSet(availableClassifiers);
    }
```

解决方案（不能只调大`-Dio.netty.maxDirectMemory`参数，因为再大他也会不断累积导致使用完）：

1. 升级lettuce客户端
2. 切换为jedis客户端

切换步骤

```xml
 <dependency>
     <groupId>org.springframework.boot</groupId>
     <artifactId>spring-boot-starter-data-redis</artifactId>
     <!--移除lettuce客户端:使用netty，性能强-->
     <exclusions>
         <exclusion>
             <groupId>io.lettuce</groupId>
             <artifactId>lettuce-core</artifactId>
         </exclusion>
     </exclusions>
</dependency>
<!--添加新的jedis客户端-->
<dependency>
    <groupId>redis.clients</groupId>
    <artifactId>jedis</artifactId>
</dependency>
```

# 高并发下缓存引发的问题

## 缓存穿透（查询永不存在的）

查询一个一定不存在的数据，由于缓存不存在会查询数据库，由于数据库也没有记录，我们没有将从数据库查出来的空记录写回缓存，这就导致每次不存在的数据都去数据库查询，失去了缓存的意义。

### 风险

利用不存在的数据进行攻击，数据库的瞬时压力增大，最终崩溃

### 解决方案

null数据也写入缓存，设置短暂的过期时间

## 缓存雪崩（大面积key同时失效）

设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，导致数据库雪崩。

### 解决方案

在原有的失效时间上增加一个随机值，比如一到五分钟随机，这样每一个缓存的过期时间的重合率就会降低。

## 缓存击穿（热点key被高并发访问）

当热点key被高并发访问时恰好过期，请求全部到DB，数据库崩溃

### 解决方案

加锁

#### 加锁方式

1. 同步代码块

```shell
public Map<String, List<Catelog2Vo>> getCatelogJsonFromDB() {
        // 接口优化：将所有的数据一次查询出来，后面的查询在该数据集中遍历查询，减少数据库的交互
        // spring中的组件都是单例的
        synchronized (this) {
            List<CategoryEntity> levelOneList = getLevelOneList();
            Map<String, List<Catelog2Vo>> collect = levelOneList.stream().collect(Collectors.toMap(k -> k.getCatId().toString(), v -> {
                // 封装catelog2VO的列表
                List<CategoryEntity> levelTwoList = list(new QueryWrapper<CategoryEntity>().eq("parent_cid", v.getCatId()));
                List<Catelog2Vo> catelog2VoList = new ArrayList<>();
                if (!CollectionUtils.isEmpty(levelTwoList)) {
                    catelog2VoList = levelTwoList.stream().map(two -> {
                        // 查询三级分类列表
                        List<CategoryEntity> levelThreeList = list(new QueryWrapper<CategoryEntity>().eq("parent_cid", two.getCatId()));
                        List<Catelog2Vo.Catelog3Vo> catelog3VoList = new ArrayList<>();
                        if (!CollectionUtils.isEmpty(levelThreeList)) {
                            catelog3VoList = levelThreeList.stream().map(three -> {
                                Catelog2Vo.Catelog3Vo catelog3Vo = new Catelog2Vo.Catelog3Vo(two.getCatId().toString(), three.getCatId().toString(), three.getName());
                                return catelog3Vo;
                            }).collect(Collectors.toList());
                        }
                        Catelog2Vo catelog2Vo = new Catelog2Vo(v.getCatId().toString(), catelog3VoList, two.getCatId().toString(), two.getName());
                        return catelog2Vo;
                    }).collect(Collectors.toList());
                }
                return catelog2VoList;
            }));
            return collect;
        }
    }
```

这种方式是锁住了，但是会排队查询数据库，是不合理的。应该是第一个查询数据后放入缓存，其他的就不去查询数据库从缓存取了。

```java
public Map<String, List<Catelog2Vo>> getCatelogJsonFromDB() {
        // 接口优化：将所有的数据一次查询出来，后面的查询在该数据集中遍历查询，减少数据库的交互
        // spring中的组件都是单例的
        synchronized (this) {
            // 得道锁之后再去缓存确认一次
            String catalogJson = stringRedisTemplate.opsForValue().get(CacheConstant.ProductCacheKeyEnum.CATALOG_JSON.getCode());
            if (StringUtils.isEmpty(catalogJson)) {
                Map<String, List<Catelog2Vo>> catelogJsonFromDB = getCatelogJsonFromDB();
                stringRedisTemplate.opsForValue().set(CacheConstant.ProductCacheKeyEnum.CATALOG_JSON.getCode(), JSON.toJSONString(catelogJsonFromDB), 1, TimeUnit.DAYS);
                return catelogJsonFromDB;
            }
            // 没有数据再去查询数据
            List<CategoryEntity> levelOneList = getLevelOneList();
            Map<String, List<Catelog2Vo>> collect = levelOneList.stream().collect(Collectors.toMap(k -> k.getCatId().toString(), v -> {
                // 封装catelog2VO的列表
                List<CategoryEntity> levelTwoList = list(new QueryWrapper<CategoryEntity>().eq("parent_cid", v.getCatId()));
                List<Catelog2Vo> catelog2VoList = new ArrayList<>();
                if (!CollectionUtils.isEmpty(levelTwoList)) {
                    catelog2VoList = levelTwoList.stream().map(two -> {
                        // 查询三级分类列表
                        List<CategoryEntity> levelThreeList = list(new QueryWrapper<CategoryEntity>().eq("parent_cid", two.getCatId()));
                        List<Catelog2Vo.Catelog3Vo> catelog3VoList = new ArrayList<>();
                        if (!CollectionUtils.isEmpty(levelThreeList)) {
                            catelog3VoList = levelThreeList.stream().map(three -> {
                                Catelog2Vo.Catelog3Vo catelog3Vo = new Catelog2Vo.Catelog3Vo(two.getCatId().toString(), three.getCatId().toString(), three.getName());
                                return catelog3Vo;
                            }).collect(Collectors.toList());
                        }
                        Catelog2Vo catelog2Vo = new Catelog2Vo(v.getCatId().toString(), catelog3VoList, two.getCatId().toString(), two.getName());
                        return catelog2Vo;
                    }).collect(Collectors.toList());
                }
                return catelog2VoList;
            }));
            return collect;
        }
```

单体应用可以实现，多个实例的时候每个实例都是各自的锁，那么有几台机器就放了这么多的线程到数据库，但是当请求分发到其它服务器之后无法实现。真正实现多实例使用同一把锁需要使用分布式锁。

#### 锁的时序性问题

上述代码单机模式下仍然会出现查询多次数据库的情况：当查询数据库的第一个线程释放之后，第二个线程已经拿到了锁，这时候上一个线程还没放进缓存，应该在锁里面把结果放入缓存

#### 分布式锁

- 原生的`redis`命令+`lua`脚本实现

```java
 public Map<String, List<Catelog2Vo>> getCatalogDataFromDBWithRedisLock() throws InterruptedException {
        String uuid = UUID.randomUUID().toString();
        // 判断是否是自己的锁和删除锁必须是原子操作
        // 获取锁和设置过期时间必须是原子操作
        // 锁的自动续期怎么做
        Boolean lock = stringRedisTemplate.opsForValue().setIfAbsent("lock", uuid, 300, TimeUnit.SECONDS);
        if (lock) {
            // 处理业务
            Map<String, List<Catelog2Vo>> dataFromDb = null;
            try {
                dataFromDb = getDataFromDb();
            } finally {
                // 原子删除锁
                String script = "if redis.call(\"get\",KEYS[1]) == ARGV[1]\n" +
                        "then\n" +
                        "    return redis.call(\"del\",KEYS[1])\n" +
                        "else\n" +
                        "    return 0\n" +
                        "end";
                Long deleteResult = stringRedisTemplate.execute(new DefaultRedisScript<Long>(script, Long.class), Arrays.asList("lock"), uuid);
                if (deleteResult > 0) {
                    //删除成功
                    System.err.println("lock: " + uuid + "删除成功");
                } else {
                    // 删除失败
                    System.err.println("lock: " + uuid + "删除失败");
                }
            }
            return dataFromDb;
        } else {
            Thread.sleep(1000L);
            return getCatalogDataFromDBWithRedisLock();
        }
    }
```



- `redission`实现

1. 引入依赖

```xml
<!-- https://mvnrepository.com/artifact/org.redisson/redisson -->
<dependency>
    <groupId>org.redisson</groupId>
    <artifactId>redisson</artifactId>
    <version>3.12.0</version>
</dependency>
```

2. 配置

https://github.com/redisson/redisson/wiki/2.-%E9%85%8D%E7%BD%AE%E6%96%B9%E6%B3%95#21-%E7%A8%8B%E5%BA%8F%E5%8C%96%E9%85%8D%E7%BD%AE%E6%96%B9%E6%B3%95

```java
package com.atguigu.gulimall.product.config;

import org.redisson.Redisson;
import org.redisson.api.RedissonClient;
import org.redisson.config.Config;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import java.io.IOException;

@Configuration
public class RedissonConfig {

    @Bean(destroyMethod="shutdown")
    RedissonClient redisson() throws IOException {
        Config config = new Config();
//        config.useClusterServers()
//                .addNodeAddress("127.0.0.1:7004");
        config.useSingleServer().setAddress("redis://192.168.56.10:6379");
        return Redisson.create(config);
    }
}
```

1. 可重入锁

```java
@GetMapping("/hello")
    @ResponseBody
    public String hello(){
        // 只要名字相同就是同一把锁
        RLock lock = redisson.getLock("my-lock");
        // 阻塞式等待，不需要一直循环
        // 业务时间长会自动续期被删掉
        // 默认上来加的锁都是30秒
        // 加锁的业务只要运行完成，不会自动续期，即使不手动解锁也会在30秒后会过期	
        lock.lock();
        try{
            Thread.sleep(30000L);
            System.err.println("加锁" + Thread.currentThread().getId());
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            // 即使没有手动解锁也会自动解锁
            lock.unlock();
            System.err.println("解锁" + Thread.currentThread().getId());
        }
        return "hello";
    }
```

2. 读写锁

```java
 /**
     * 读写锁测试
     * @return
     * @throws InterruptedException
     *
     * 写 + 读:等待写锁释放
     * 写 + 写：阻塞方式
     * 读 + 写：等待读锁释放
     * 读 + 读：相当于无锁，并发读只会在redis中记录好读锁记录，不会阻塞
     * 总结：只要有写的存在都会等待
     */
    @GetMapping("/write")
    @ResponseBody
    public String writeValue() throws InterruptedException {
        RReadWriteLock readWriteLock = redisson.getReadWriteLock("rw-lock");
        String str = UUID.randomUUID().toString();
        // 改数据加写锁
        RLock rLock = readWriteLock.writeLock();
        rLock.lock();
        redisTemplate.opsForValue().set("writeValue", str);
        Thread.sleep(30000);
        System.err.println("释放锁的时间：" + LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss")));
        rLock.unlock();
        return str;
    }

    @GetMapping("/read")
    @ResponseBody
    public String readValue() throws InterruptedException {
        RReadWriteLock readWriteLock = redisson.getReadWriteLock("rw-lock");
        // 读数据加读锁
        RLock rLock = readWriteLock.readLock();
        rLock.lock();
        System.err.println("获取到锁的时间：" + LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss")));
        String writeValue = redisTemplate.opsForValue().get("writeValue");
        rLock.unlock();
        return writeValue;
    }
```

3. 闭锁(`CountDownLatch`)

```java
/**
     * 闭锁测试：放假，锁门：五个班全部走完才能锁门
     */
    @GetMapping("/lockdoor")
    @ResponseBody
    public String lockDoor() {
        RCountDownLatch door = redisson.getCountDownLatch("door");
        door.trySetCount(5); // 总的数量
        door.await();
        return "人走完了，放假了...";
    }


    @GetMapping("/go/{id}")
    @ResponseBody
    public String go(@PathVariable("id")int id) {
        RCountDownLatch door = redisson.getCountDownLatch("door");
        door.countDown();// 总数量减一
        return id + "班的人走完了";
    }
```

4. 信号量（`Semaphore`）,分布式限流

```java
/**
     * redis中存储了以锁的名字为key的车位数量
     * 信号量测试：车库停车
     *  占一个车位少一个
     */
    @GetMapping("/park")
    @ResponseBody
    public String park() throws InterruptedException {
        RSemaphore park = redisson.getSemaphore("park");
        park.acquire(); // 占一个车位，当没有剩余车位时阻塞等待
//        boolean b = park.tryAcquire();// 占一个车位，当没有车位时返回false
        return "ok";
    }

    /**
     * 信号量测试：车库停车
     *  开走车位增加一个
     */
    @GetMapping("/park")
    @ResponseBody
    public String relase() throws InterruptedException {
        RSemaphore park = redisson.getSemaphore("park");
        park.release(); // 释放个车位，增加park数量
        return "ok";
    }
```

# 改造获取三级分类数据业务

```java
// 使用分布式锁获取三级分类数据
    private Map<String, List<Catelog2Vo>> getCatalogDataFromDBWithRedissonLock() {
        RLock lock = redissonClient.getLock(CacheConstant.ProductCacheKeyEnum.CATALOG_JSON_LOCK.getCode());
        lock.lock();
        Map<String, List<Catelog2Vo>> returnMap = null;
        try {
            returnMap = getDataFromDb();
        } finally {
            lock.unlock();
        }
        return returnMap;
    }
```

# 缓存数据的一致性

1. 双写模式

原理：修改数据库之后就修改缓存中的数据

漏洞：并发修改的时候，修改数据库的操作和修改缓存的数据的操作不是原子操作，造成缓存脏数据

方案：修改数据库和修改缓存加锁

2. 失效模式

原理：数据库改完直接将缓存中的数据删掉，等待下次查询的时候主动更新缓存

漏洞：修改完数据库之后，查数据的时候正在修改数据库且还没修改完。

加锁之后系统笨重，经常修改的需不需要放缓存。